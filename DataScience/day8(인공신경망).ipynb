{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNbIyxa5/1oOZ3mWOAsJ7hA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jh868/Python/blob/main/DataScience/day8(%EC%9D%B8%EA%B3%B5%EC%8B%A0%EA%B2%BD%EB%A7%9D).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 인공신경망\n",
        "실제 인간의 뇌에서 수행되는 신경망 방식을 사용한 컴퓨터 연산 방법   \n",
        "실제 뇌에서 뉴런간 정보 전달 방식을 모델링한 것"
      ],
      "metadata": {
        "id": "aC3Z7YvAA1Kr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 퍼셉트론\n",
        "신경망의 한 종류   \n",
        "\n",
        "입력값 X 를 가중치와 곱해서 모두 더한 값이 임계값 기준이 있는 노드"
      ],
      "metadata": {
        "id": "c7BgFW99GMp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('data.csv')"
      ],
      "metadata": {
        "id": "R0H1j4QmQlQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "mxGIi6DLQmp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    self.x1 = df.iloc[:,0].values\n",
        "    self.x2 = df.iloc[:,1].values\n",
        "    self.y = df.iloc[:,2].values\n",
        "    self.length = len(df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.FloatTensor([self.x1[index], self.x2[index]])\n",
        "    y = torch.FloatTensor([self.y[index]])\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomModel, self).__init__()\n",
        "\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Linear(2,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer(x)\n",
        "    return x\n",
        "\n",
        "train_dataset = CustomDataset('data.csv')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = CustomModel().to(device)\n",
        "criterion = nn.BCELoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10000):\n",
        "  cost = 0.0\n",
        "  for x, y in train_dataloader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cost += loss\n",
        "\n",
        "  cost = cost/len(train_dataloader)\n",
        "\n",
        "  if (epoch + 1) % 1000 ==0:\n",
        "    print(f'Epoch : {epoch+1:4d}, Cost:{cost :.3f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  inputs = torch.FloatTensor([\n",
        "      [0,0],\n",
        "      [0,1],\n",
        "      [1,0],\n",
        "      [1,1]\n",
        "  ]).to(device)\n",
        "\n",
        "  outputs = model(inputs)\n",
        "\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "1poFGMQ2Q5Fn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class fruit():\n",
        "  def __init__(self) -> None:\n",
        "    self.cnt = 0\n",
        "    self.name = []\n",
        "\n",
        "  def add_fruit(self, name, size):\n",
        "     self.name.append(name)\n",
        "     self.cnt += 1\n",
        "     return True\n",
        "\n",
        "  def set_fruit(self, new_name):\n",
        "    self.name = new_name\n",
        "\n",
        "  def get_item(self):\n",
        "    return self.name\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.cnt"
      ],
      "metadata": {
        "id": "5DRmr7DXRMO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fruit_class = fruit()"
      ],
      "metadata": {
        "id": "aD2blFYfRRC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fruit_class.add_fruit('apple',10)\n",
        "fruit_class.add_fruit('banana',10)\n",
        "fruit_class.add_fruit('orange',10)"
      ],
      "metadata": {
        "id": "ijlIIoRjRSrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(fruit_class)"
      ],
      "metadata": {
        "id": "auJkH79KRUbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dir(fruit_class)"
      ],
      "metadata": {
        "id": "L95csAOkRWPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fruit_class.get_item()"
      ],
      "metadata": {
        "id": "bnlewYiKRYIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fruit_class.name = ['1','2','3']"
      ],
      "metadata": {
        "id": "_YjYHtwHRZxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fruit_class.name"
      ],
      "metadata": {
        "id": "_6jUX1PlRbR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 다층퍼셉트론 모델"
      ],
      "metadata": {
        "id": "O9CUMa4ZRcu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    self.x1 = df.iloc[:, 0].values\n",
        "    self.x2 = df.iloc[:,1].values\n",
        "    self.y = df.iloc[:,2].values\n",
        "    self.length = len(df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.FloatTensor([self.x1[index], self.x2[index]])\n",
        "    y = torch.FloatTensor([self.y[index]])\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomModel, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(2,2),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Linear(2,1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    return x\n",
        "\n",
        "train_dataset = CustomDataset('data.csv')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, drop_last=True)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "model = CustomModel().to(device)\n",
        "criterion = nn.BCELoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(10000):\n",
        "  cost = 0.0\n",
        "  for x,y in train_dataloader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cost += loss\n",
        "\n",
        "  cost = cost/len(train_dataloader)\n",
        "\n",
        "  if (epoch + 1) % 1000 ==0:\n",
        "    print(f'Epoch : {epoch+1:4d}, Cost : {cost:.3f}')\n",
        "\n",
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  input = torch.FloatTensor([\n",
        "      [0,0],\n",
        "      [0,1],\n",
        "      [1,0],\n",
        "      [1,1]\n",
        "  ]).to(device)\n",
        "\n",
        "  outputs = model(input)\n",
        "\n",
        "print(outputs)\n",
        "print(outputs<=0.5)"
      ],
      "metadata": {
        "id": "5siN9p5ZbV3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install koreanize-matplotlib\n",
        "import numpy as np\n",
        "import koreanize_matplotlib\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "BQTtAg_NbX-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def step(x): # 연속함수가 아니라 미분 안됨\n",
        "  return np.array(x >0, dtype=np.int)\n",
        "\n",
        "x = np.arange(-5.0,5.0,0.1)\n",
        "y = step(x)\n",
        "plt.title('Step Function')\n",
        "plt.plot(x,y)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FlAND_qCbZ6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시그모이드 함수\n",
        "def sigmoid(x):\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "y = sigmoid(x)\n",
        "plt.plot(x,y)\n",
        "plt.title('Sigmoid Function')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FVQ6-WzIbbxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시그모이드와 비슷하지만 음수값부터 시작\n",
        "x = np.arange(-5.0,5.0,0.1)\n",
        "y = np.tanh(x)\n",
        "plt.plot(x,y)\n",
        "plt.grid()\n",
        "plt.title('Tanh function')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CzgR5fbYcdLX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ReLU\n",
        "def relu(x):\n",
        "  return np.maximum(0,x)\n",
        "\n",
        "x = np.arange(-5.0, 5.0, 0.1)\n",
        "plt.plot(x,relu(x))\n",
        "plt.grid()\n",
        "plt.title('ReLU Function')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J84NZ4sacy7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = 0.1\n",
        "\n",
        "def leaky_relu(x):\n",
        "  return np.maximum(a*x,x)\n",
        "\n",
        "plt.plot(x,leaky_relu(x))\n",
        "plt.grid()\n",
        "plt.title('Leaky ReLU')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mOUlIuk7dRlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Softmax\n",
        "x = np.arange(-5.0,5.0,0.1)\n",
        "y = np.exp(x)/np.sum(np.exp(x))\n",
        "\n",
        "plt.plot(x,y)\n",
        "plt.title('Softmax Function')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fwuwWiAweN4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# K-Nearest Neighbors\n",
        "\n",
        "새로운 데이터(x)와 가장 가까운 k개의 데이터를 통해 x를 분류하는 방법   \n",
        "\n",
        "- euclidean distance\n",
        "$$\\sqrt{(x_1-μ_1)^2 + (x_2-μ_2)^2+ ⋯ + (x_p-μ_p)^2}$$\n",
        "\n",
        "- manhattan distance\n",
        "$$|x_1-μ_1|+|x_2-μ_2|+⋯+|x_p-μ_p|$$\n",
        "\n",
        "      변수의 값이 가지는 스케일의 차이가 모델 학습에 영향을 미치는 것을 막기 위해 스케일링 수행이 필요\n",
        "      각 변수의 값 차이가 가졌던 정보는 남아있돌록 스케일링"
      ],
      "metadata": {
        "id": "7UsfSvc_fD04"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "9MftDEtt51Rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_price = pd.read_csv('train.csv')\n",
        "print(mobile_price.shape)\n",
        "mobile_price.head()"
      ],
      "metadata": {
        "id": "Yn3k3RCa6mER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_price['price_range'].unique()"
      ],
      "metadata": {
        "id": "ZCxOJ9JF6nYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobile_price.columns"
      ],
      "metadata": {
        "id": "va8QjNku9wID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns = mobile_price.columns\n",
        "\n",
        "X = mobile_price[columns[:-1]]\n",
        "y = mobile_price[columns[-1]]\n",
        "\n",
        "SC = StandardScaler()\n",
        "X = SC.fit_transform(X)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=0)\n"
      ],
      "metadata": {
        "id": "BEhuO9fE9xgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train),len(x_test))"
      ],
      "metadata": {
        "id": "mrrEvRwg9zLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(1, 12):\n",
        "  knn_model=KNeighborsClassifier(n_neighbors=i,\n",
        "                                metric='manhattan').fit(x_train, y_train)\n",
        "  print(knn_model.score(x_train, y_train))\n",
        "  print(knn_model.score(x_test, y_test))\n",
        "  print('='*10)"
      ],
      "metadata": {
        "id": "80MP6cff90h2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model=KNeighborsClassifier(n_neighbors=8,\n",
        "                              metric='manhattan').fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "c4faNBxe917q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model.predict_proba(x_test)[0]"
      ],
      "metadata": {
        "id": "7oSRUhQ-93qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_model.predict(x_test)[0]"
      ],
      "metadata": {
        "id": "Whp3K3CP94_X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    self.x1 = df.iloc[:, 0].values\n",
        "    self.x2 = df.iloc[:,1].values\n",
        "    self.x3 = df.iloc[:, 2].values\n",
        "    self.x4 = df.iloc[:,3].values\n",
        "    self.x5 = df.iloc[:, 4].values\n",
        "    self.x6 = df.iloc[:,5].values\n",
        "    self.x7 = df.iloc[:, 6].values\n",
        "    self.x8 = df.iloc[:,7].values\n",
        "    self.x9 = df.iloc[:,8].values\n",
        "    self.y = df.iloc[:,9].values\n",
        "    self.length = len(df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.FloatTensor([self.x1[index], self.x2[index],self.x3[index], \n",
        "                           self.x4[index],self.x5[index], self.x6[index],\n",
        "                           self.x7[index], self.x8[index],self.x9[index]])\n",
        "    y = torch.LongTensor(self.y-1)[index]\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomModel, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(9,18),\n",
        "        # nn.Sigmoid()\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Linear(18,7),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    return x\n",
        "\n",
        "train_dataset = CustomDataset('glass.csv')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "device = 'cuda'\n",
        "print(device)\n",
        "\n",
        "model = CustomModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100000):\n",
        "  cost = 0.0\n",
        "  for x,y in train_dataloader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cost += loss\n",
        "\n",
        "  cost = cost/len(train_dataloader)\n",
        "\n",
        "  if (epoch + 1) % 1000 ==0:\n",
        "    print(f'Epoch : {epoch+1:4d}, Cost : {cost:.3f}')\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   model.eval()\n",
        "#   print(glass[:10,:-1])\n",
        "#   input = torch.FloatTensor([\n",
        "#       [0,0],\n",
        "#       [0,1],\n",
        "#       [1,0],\n",
        "#       [1,1]\n",
        "#   ]).to(device)\n",
        "\n",
        "#   outputs = model(input)\n",
        "\n",
        "# print(outputs)\n",
        "# print(outputs<=0.5)"
      ],
      "metadata": {
        "id": "6LskJL0V96ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이어를 마냥 늘리고 줄인다고 좋은건 아님\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    self.x1 = df.iloc[:, 0].values\n",
        "    self.x2 = df.iloc[:,1].values\n",
        "    self.x3 = df.iloc[:, 2].values\n",
        "    self.x4 = df.iloc[:,3].values\n",
        "    self.x5 = df.iloc[:, 4].values\n",
        "    self.x6 = df.iloc[:,5].values\n",
        "    self.x7 = df.iloc[:, 6].values\n",
        "    self.x8 = df.iloc[:,7].values\n",
        "    self.x9 = df.iloc[:,8].values\n",
        "    self.y = df.iloc[:,9].values\n",
        "    self.length = len(df)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.FloatTensor([self.x1[index], self.x2[index],self.x3[index], \n",
        "                           self.x4[index],self.x5[index], self.x6[index],\n",
        "                           self.x7[index], self.x8[index],self.x9[index]])\n",
        "    y = torch.LongTensor(self.y-1)[index]\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomModel, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(9,256),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer2 = nn.Sequential(\n",
        "        nn.Linear(256,512),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer3 = nn.Sequential(\n",
        "        nn.Linear(512,128),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.layer4 = nn.Sequential(\n",
        "        nn.Linear(128,18),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "    self.output_layer = nn.Sequential(\n",
        "        nn.Linear(18,7),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.layer1(x)\n",
        "    x = self.layer2(x)\n",
        "    return x\n",
        "\n",
        "train_dataset = CustomDataset('glass.csv')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "device = 'cuda'\n",
        "print(device)\n",
        "\n",
        "model = CustomModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(100000):\n",
        "  cost = 0.0\n",
        "  for x,y in train_dataloader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cost += loss\n",
        "\n",
        "  cost = cost/len(train_dataloader)\n",
        "\n",
        "  if (epoch + 1) % 1000 ==0:\n",
        "    print(f'Epoch : {epoch+1:4d}, Cost : {cost:.3f}')"
      ],
      "metadata": {
        "id": "tZegFhCWJf1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self, file_path):\n",
        "    df = pd.read_csv(file_path)\n",
        "    self.a = df.iloc[:, 0].values\n",
        "    self.b = df.iloc[:,1].values\n",
        "    self.c = df.iloc[:, 2].values\n",
        "    self.y = df.iloc[:, 3].values\n",
        "    self.y = list(map(self.string_to_vector, self.y))\n",
        "    self.length = len(df)\n",
        "\n",
        "  def string_to_vector(self, value):\n",
        "    key_value = {'obtuse triangle':2, 'acute triangle':1, 'right triangle':0}\n",
        "    return key_value[value]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    x = torch.FloatTensor(sorted([self.a[index], self.b[index], self.c[index]]))\n",
        "    y = torch.LongTensor(self.y)[index]\n",
        "    return x,y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.length\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CustomModel, self).__init__()\n",
        "\n",
        "    self.layer = nn.Sequential(\n",
        "        nn.Linear(3, 3)\n",
        "    )\n",
        "  def forward(self,x):\n",
        "    return self.layer(x)\n",
        "\n",
        "train_dataset = CustomDataset('dataset.csv')\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, drop_last=True)\n",
        "\n",
        "device = 'cuda'\n",
        "\n",
        "model = CustomModel().to(device)\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "for epoch in range(10000):\n",
        "  cost = 0.0\n",
        "  for x, y in train_dataloader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "\n",
        "    output = model(x)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    cost += loss\n",
        "\n",
        "  cost = cost/len(train_dataloader)\n",
        "\n",
        "  if (epoch + 1) % 1000 ==0:\n",
        "    print(f'Epoch : {epoch+1:4d}, Cost : {cost:.3f}')"
      ],
      "metadata": {
        "id": "xRk9ByP3N3C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  model.eval()\n",
        "  classes = {2:'obtuse triangle', 1:'acute triangle', 0:'right triangle'}\n",
        "  inputs = torch.FloatTensor(\n",
        "      [\n",
        "          [3.0,4.0,5.0],\n",
        "       [3, 3, 3]\n",
        "       \n",
        "      ]\n",
        "  ).to(device)"
      ],
      "metadata": {
        "id": "nVTwMRdzORjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(inputs)"
      ],
      "metadata": {
        "id": "Sxnj7orPR4xI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "print(torch.round(F.softmax(outputs, dim=1), decimals=2))\n",
        "print(outputs.argmax(1))\n",
        "print(list(map(classes.get, outputs.argmax(1).tolist())))"
      ],
      "metadata": {
        "id": "p4ED832_R6Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LRWEFzaPSAYt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}